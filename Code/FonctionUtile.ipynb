{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Here are present the function that are useful for the 2 first part of the Project. \n",
        "#We use it to make the code more readable"
      ],
      "metadata": {
        "id": "zw9k8uEdHAZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd \n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import TransformerMixin\n",
        "import seaborn as sns\n",
        "sns.set_style(\"whitegrid\")\n",
        "import string\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from pprint import pprint\n",
        "import functools\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "from transformers import AutoModelForSequenceClassification, CamembertForMaskedLM, AutoTokenizer, AutoConfig\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "kKTTOMkmK_5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -U spacy\n",
        "# Download the French language model\n",
        "!python -m spacy download fr"
      ],
      "metadata": {
        "id": "-y7pZehIWHWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp = spacy.load('fr_core_news_sm')"
      ],
      "metadata": {
        "id": "F4WgFBm9WKs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to print a classification report "
      ],
      "metadata": {
        "id": "qRivZQvWGk5T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_ktdjGNF77X"
      },
      "outputs": [],
      "source": [
        "def Evaluate(true, pred):\n",
        "    precision = precision_score(true, pred, average='weighted')\n",
        "    recall = recall_score(true, pred, average='weighted')\n",
        "    f1 = f1_score(true, pred, average='weighted')\n",
        "    accuracy = accuracy_score(true, pred)\n",
        "    print(f\"CLASSIFICATION REPORT:\\n\\tAccuracy: {accuracy:.4f}\\n\\tPrecision: {precision:.4f}\\n\\tRecall: {recall:.4f}\\n\\tF1_Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to plot a confusion matrix"
      ],
      "metadata": {
        "id": "Gnoy3tZMGtb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Accuracy_conf_mat(y_test, y_pred_test):\n",
        "  conf_mat = confusion_matrix(y_test, y_pred_test)\n",
        "  fig, ax = plt.subplots(figsize=(10,10))\n",
        "  sns.heatmap(conf_mat, annot=True, fmt='d')\n",
        "  plt.ylabel('Actual')\n",
        "  plt.xlabel('Predicted')\n",
        "  ax.xaxis.set_ticklabels(['A1', 'A2','B1','B2','C1','C2']); ax.yaxis.set_ticklabels(['A1', 'A2','B1','B2','C1','C2']);\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "3gCFka99GSc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to print a sample of sentences that are not correctly classified"
      ],
      "metadata": {
        "id": "vmphUeRfGwSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Sentences_badly_classified(a,b, X_test, prediction, y_test):\n",
        "  classification_sample = list(enumerate(zip(X_test, prediction, y_test)))\n",
        "  classification_sample = classification_sample[a:b] #take a sample\n",
        "  for (row_index, (input, prediction, label)) in classification_sample :\n",
        "    if prediction != label:\n",
        "      print((input, 'has been classified as ', prediction, 'and should be ', label))"
      ],
      "metadata": {
        "id": "aaRIleJIGXGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to return a prediction"
      ],
      "metadata": {
        "id": "pvT34dXBG2-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Prediction(model, test):\n",
        "  prediction = model.predict(test)\n",
        "  return prediction"
      ],
      "metadata": {
        "id": "8oo5tWkbGaaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to return the DataFrame in the correct form for submission\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7Q98Jg043ycj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def submission(id, prediction):\n",
        "  d = {'id': id, 'difficulty': prediction}\n",
        "  df = pd.DataFrame(data=d)\n",
        "  return df"
      ],
      "metadata": {
        "id": "YrVcS0cR3xN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punctuations = string.punctuation\n",
        "stop_words = spacy.lang.fr.stop_words.STOP_WORDS"
      ],
      "metadata": {
        "id": "2foGJIwTVrXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spacy_tokenizer(sentence):\n",
        "    numbers = \"0123456789\"\n",
        "    # Create token object, which is used to create documents with linguistic annotations.\n",
        "    mytokens = sp(sentence)\n",
        "\n",
        "    # Lemmatize each token and convert each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() for word in mytokens ]\n",
        "    ## alternative way\n",
        "    # mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "\n",
        "    # Remove stop words and punctuation\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "    mytokens_2 = []\n",
        "    for word in mytokens:\n",
        "      for char in word:\n",
        "        if (char in punctuations) or (char in numbers):\n",
        "          word = word.replace(char, \"\")\n",
        "      if word != \"\":\n",
        "        mytokens_2.append(word)\n",
        "\n",
        "    # Return preprocessed list of tokens\n",
        "    return mytokens_2"
      ],
      "metadata": {
        "id": "w8C5R6KhMDFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def configs():\n",
        "\n",
        "    models = list()\n",
        "    \n",
        "    # Define config lists\n",
        "    ngram_range = [(1,1), (1,2), (1, 3), (2, 2), (2, 3), (3, 3)]\n",
        "    min_df = [1]\n",
        "    max_df = [1.0]\n",
        "    analyzer=['word', 'char']\n",
        "    \n",
        "    # Create config instances\n",
        "    for n in ngram_range:\n",
        "        for i in min_df:\n",
        "            for j in max_df:\n",
        "              for a in analyzer:\n",
        "                    cfg = [n, i, j, a]\n",
        "                    models.append(cfg)\n",
        "    return models\n",
        "\n",
        "configs = configs()\n",
        "configs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk1Tf-arMKBz",
        "outputId": "8b0a51d4-0548-44bc-d9b8-15a735c95435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(1, 1), 1, 1.0, 'word'],\n",
              " [(1, 1), 1, 1.0, 'char'],\n",
              " [(1, 2), 1, 1.0, 'word'],\n",
              " [(1, 2), 1, 1.0, 'char'],\n",
              " [(1, 3), 1, 1.0, 'word'],\n",
              " [(1, 3), 1, 1.0, 'char'],\n",
              " [(2, 2), 1, 1.0, 'word'],\n",
              " [(2, 2), 1, 1.0, 'char'],\n",
              " [(2, 3), 1, 1.0, 'word'],\n",
              " [(2, 3), 1, 1.0, 'char']]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}