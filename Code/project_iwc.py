# -*- coding: utf-8 -*-
"""project_IWC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/Thomasvidalenc/DMML2022_IWC/blob/main/project_IWC.ipynb
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

https://github.com/Thomasvidalenc/DMML2022_IWC/blob/19d41b8b8f952c29feb538062c590ca2b390e799/Code/Project.ipynb

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# ! pip install kaggle

!mkdir ~/.kaggle

!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json

!mkdir data

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# ! kaggle competitions download -c detecting-french-texts-difficulty-level-2022

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !unzip "detecting-french-texts-difficulty-level-2022.zip" -d data

import pandas as pd
import numpy as np
df_training = pd.read_csv('/content/data/training_data.csv')
df_test = pd.read_csv('/content/data/unlabelled_test_data.csv')
df_sample = pd.read_csv('/content/data/sample_submission.csv')

"""Let's take a look to our data"""

df_training.head()

"""4. Train your models

Set your X and y variables. Set the random_state=0 Split the data into a train and test set using the following parameters train_test_split(X, y, test_size=0.2, random_state=0).

4.1.Baseline

What is the baseline for this classification problem?

Import our package
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd 
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, OrdinalEncoder
from sklearn.linear_model import LogisticRegression, LogisticRegressionCV
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import spacy
from spacy import displacy
from sklearn.feature_extraction.text import  TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.base import TransformerMixin
from sklearn.pipeline import Pipeline
import string
from spacy.lang.en.stop_words import STOP_WORDS
from spacy.lang.fr import French
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score,classification_report

np.random.seed = 0

base_rate = df_training['difficulty'].value_counts().max() / len(df_training['difficulty'])
base_rate #result must be better than that

"""Define X and Y"""

X = df_training['sentence']
y = df_training['difficulty']

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install -U spacy
# # Download the French language model
# !python -m spacy download fr

sp = spacy.load('fr_core_news_sm')

tfidf_vector = TfidfVectorizer()

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)

"""#4.2. Logistic Regression (without data cleaning)

Train a simple logistic regression model using a Tfidf vectoriser.
"""

# Tfidf gives the rare term high weight and gives the common term low weight
classifier = LogisticRegression()

# Create pipeline
## The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.
pipe = Pipeline([('vectorizer', tfidf_vector),
                 ('classifier', classifier)])

# Fit model on training set
pipe.fit(X_train, y_train)

"""Calculate accuracy, precision, recall and F1 score on the test set."""

def evaluate(true, pred):
    precision = precision_score(true, pred, average='weighted')
    recall = recall_score(true, pred, average='weighted')
    f1 = f1_score(true, pred, average='weighted')
    accuracy = accuracy_score(y_test, y_pred)
    print(f"CLASSIFICATION REPORT:\n\tAccuracy: {accuracy:.4f}\n\tPrecision: {precision:.4f}\n\tRecall: {recall:.4f}\n\tF1_Score: {f1:.4f}")

# Predictions
y_pred = pipe.predict(X_test)
evaluate(y_test, y_pred)

"""Have a look at the confusion matrix and identify a few examples of sentences that are not well classified."""

def accuracy_conf_mat(y_test, y_pred_test):
  conf_mat = confusion_matrix(y_test, y_pred)
  fig, ax = plt.subplots(figsize=(10,10))
  sns.heatmap(conf_mat, annot=True, fmt='d')
  plt.ylabel('Actual')
  plt.xlabel('Predicted')
  ax.xaxis.set_ticklabels(['A1', 'A2','B1','B2','C1','C2']); ax.yaxis.set_ticklabels(['A1', 'A2','B1','B2','C1','C2']);
  plt.show()

accuracy_conf_mat(y_test, y_pred)

"""We implement a function that returns a sample of sentences that are not correctly classified"""

def sentences_badly_classified(a,b):
  classification_sample = list(enumerate(zip(X_test, y_pred, y_test)))
  classification_sample = classification_sample[a:b] #take a sample
  for (row_index, (input, prediction, label)) in classification_sample :
    if prediction != label:
      print((input, 'has been classified as ', prediction, 'and should be ', label))

"""Let's take a look to the sentences that are not correctly classified in the first five sentences of our X test."""

sentences_badly_classified(0,5)

"""Generate your first predictions on the unlabelled_test_data.csv. make sure your predictions match the format of the unlabelled_test_data.csv"""

X_test2 = df_test['sentence']
y_pred = pipe.predict(X_test2)
y_pred

"""I take the opportunity to make my first prediction csv file"""

a = pd.DataFrame(y_pred)
b = pd.DataFrame(df_test['id'])
a = a[0]
b['difficulty'] = a
b.to_csv('premiertestkaggle.csv', header=True, index=False)

"""#4.3. KNN (without data cleaning)
Train a KNN classification model using a Tfidf vectoriser. Show the accuracy, precision, recall and F1 score on the test set.


"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier()
pipe_knn = Pipeline([('vectorizer', tfidf_vector),
                 ('classifier', knn)])

# Fit model on training set
pipe_knn.fit(X_train, y_train)

y_pred = pipe_knn.predict(X_test)
evaluate(y_test, y_pred)

"""Try to improve it by tuning the hyper parameters(n_neighbors,  p, weights) with a GridSearchCV."""

from sklearn.model_selection import GridSearchCV

knn_grid = {'n_neighbors' : np.arange(start=1, stop=10, step=1),
            'p': np.arange(1,3),
            'weights' : ['uniform', 'distance']}
knn_cv = GridSearchCV(knn, knn_grid, cv = 5)
pipe_grid_knn = Pipeline([('vectorizer', tfidf_vector), ('knn_cv', knn_cv)])

pipe_grid_knn.fit(X_train, y_train)
print('Best hyperparameters:', knn_cv.best_params_)

knn2 = KNeighborsClassifier(n_neighbors=4, p = 2, weights = 'distance')
pipe_knn_2 = Pipeline([('vectorizer', tfidf_vector),
                 ('classifier', knn2)])
#I tried the possibilites manually
pipe_knn_2.fit(X_train, y_train)

y_pred = pipe_knn_2.predict(X_test)
evaluate(y_test,y_pred)

"""#4.4. Decision Tree Classifier (without data cleaning)
Train a Decison Tree classifier, using a Tfidf vectoriser. Show the accuracy, precision, recall and F1 score on the test set.
"""

from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV

#Choose random state of 0 arbitrarly to don't have fluctuations in my values
dec = DecisionTreeClassifier(random_state = 0)
pipe_dec = Pipeline([('vectorizer', tfidf_vector),
                 ('classifier', dec)])
# Fit model on training set
pipe_dec.fit(X_train, y_train)

y_pred = pipe_dec.predict(X_test)
evaluate(y_test, y_pred)

"""Try to improve it by tuning the hyper parameters (max_depth, the depth of the decision tree). I try it manually"""

grid_dec = {'max_depth': np.arange(5,25, 1)}
dec_CV = GridSearchCV(dec, grid_dec, cv = 5)
pipe_grid_dec = Pipeline([('vectorizer', TfidfVectorizer()), ('dec', dec_CV)])

pipe_grid_dec.fit(X_train, y_train)
pred = pipe_grid_dec.predict(X_test)
print("Hyperparameters:", dec_tree_CV.best_params_)
evaluate(y_test, pred)

score, matrix = get_score(y_test, pred, "Decision Tree")

scores.append(score)
matrixes.append(matrixes)

#I try the possibilities manually and i keep the best one
dec2 = DecisionTreeClassifier(max_depth=16, random_state = 0)
pipe_dec_2= Pipeline([('vectorizer', tfidf_vector),
                 ('classifier', dec2)])
#I tried the possibilites manually

# Fit model on training set
pipe_dec_2.fit(X_train, y_train)

y_pred = pipe_dec_2.predict(X_test)
evaluate(y_test, y_pred)

"""#4.5. Random Forest Classifier (without data cleaning)

Try a Random Forest Classifier, using a Tfidf vectoriser. Show the accuracy, precision, recall and F1 score on the test set.
"""

from sklearn.ensemble import RandomForestClassifier
RDC = RandomForestClassifier()

pipe_RDC = Pipeline([('vectorizer', tfidf_vector),
                 ('classifier', RDC)])
#I tried the possibilites manually

# Fit model on training set
pipe_RDC.fit(X_train, y_train)

y_pred = pipe_RDC.predict(X_test)
accuracy_test_log = accuracy_score(y_test, y_pred)
print('accuracy test: '+ str(accuracy_test_log))
precision_log = precision_score(y_test, y_pred,average='weighted')
recall_log = recall_score(y_test, y_pred,average='weighted')
f1_log = f1_score(y_test, y_pred,average='weighted')
print('precision: '+ str(precision_log))
print('recall: '+ str(recall_log))
print('f1: '+ str(f1_log))

"""#4.6 other model

Let's have a look to our datas
"""

df_training['difficulty'].value_counts().plot(kind = 'bar')

df_training.info()

df_training.isnull().sum()

"""Let's Encode our datas"""

df_training['label'] = df_training['difficulty']
df_training['sentence'] = df_training['sentence'].astype('string')

df_training['label'] = [0 if x == 'A1'
                   else 1 if x == 'A2'
                   else 2 if x == 'B1'
                   else 3 if x == 'B2'
                   else 4 if x == 'C1'
                   else 5
                   for x in df_training.difficulty]

df_training.info()

oe=OrdinalEncoder()

# set the order of your categories
oe.set_params(categories= [['0', '1', '2','3','4','5']])

# fit-transform a dataframe of the categorical age variable
df_training['label']= oe.fit_transform(df_training[['label']])

# double check your encoder used the categories in the right order
oe.categories_

df_training['label'] = df_training['label'].astype(int)
df_training = df_training.drop(['id'], axis = 1)

df_training

punctuations = string.punctuation
stop_words = spacy.lang.fr.stop_words.STOP_WORDS

df_new = pd.concat([df[df["oe_difficulty"] == 0].sample(len(df[df["oe_difficulty"] == 3])), df[df["oe_difficulty"] == 1].sample(len(df[df["oe_difficulty"] == 3])), df[df["oe_difficulty"] == 2].sample(len(df[df["oe_difficulty"] == 3])), df[df["oe_difficulty"] == 3],df[df["oe_difficulty"] == 4].sample(len(df[df["oe_difficulty"] == 3])),df[df["oe_difficulty"] == 5].sample(len(df[df["oe_difficulty"] == 3]))], axis=0).reset_index()
df_new.info()

X = df_new['sentence']
y = df_new['oe_difficulty']

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)

# Create tokenizer function
def spacy_tokenizer(sentence):
    numbers = "0123456789"
    # Create token object, which is used to create documents with linguistic annotations.
    mytokens = sp(sentence)

    # Lemmatize each token and convert each token into lowercase
    mytokens = [ word.lemma_.lower().strip() for word in mytokens ]
    ## alternative way
    # mytokens = [ word.lemma_.lower().strip() if word.lemma_ != "-PRON-" else word.lower_ for word in mytokens ]

    # Remove stop words and punctuation
    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]
    mytokens_2 = []
    for word in mytokens:
      for char in word:
        if (char in punctuations) or (char in numbers):
          word = word.replace(char, "")
      if word != "":
        mytokens_2.append(word)

    # Return preprocessed list of tokens
    return mytokens

# Create list of configs
def configs():

    models = list()
    
    # Define config lists
    ngram_range = [(1,1), (1,2), (1, 3), (2, 2), (2, 3), (3, 3)]
    min_df = [1]
    max_df = [1.0]
    analyzer=['word', 'char']
    
    # Create config instances
    for n in ngram_range:
        for i in min_df:
            for j in max_df:
              for a in analyzer:
                    cfg = [n, i, j, a]
                    models.append(cfg)
    return models

configs = configs()
configs[:10]

from sklearn import svm

result = []
for config in configs:

    # Redefine vectorizer
    tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer, 
                                   ngram_range=config[0],
                                   min_df=config[1], max_df=config[2], analyzer=config[3])

    # Define classifier
    clf = svm.SVC()

    # Create pipeline
    pipe = Pipeline([('vectorizer', tfidf_vector),
                 ('classifier', clf)])

    # Fit model on training set
    pipe.fit(X_train, y_train)

    # Predictions
    y_pred = pipe.predict(X_test)

    # Print accuracy on test set
    print("CONFIG: ", config)
    print("Accuracy ", accuracy_score(y_test, y_pred))
    print("-----------------------")

    # Append to result
    result.append([config, accuracy_score(y_test, y_pred)])

"""CONFIG:  [(2, 3), 1, 1.0, 'char']
Accuracy  0.5210084033613446
"""

result = []
for config in configs:

    # Redefine vectorizer
    tfidf_vector = TfidfVectorizer(ngram_range=config[0],
                                   min_df=config[1], max_df=config[2], analyzer=config[3])

    # Define classifier
    classifier = LogisticRegression()

    # Create pipeline
    pipe = Pipeline([('vectorizer', tfidf_vector),
                 ('classifier', classifier)])

    # Fit model on training set
    pipe.fit(X_train, y_train)

    # Predictions
    y_pred = pipe.predict(X_test)

    # Print accuracy on test set
    print("CONFIG: ", config)
    print("Accuracy ", accuracy_score(y_test, y_pred))
    print("-----------------------")

    # Append to result
    result.append([config, accuracy_score(y_test, y_pred)])

"""CONFIG: [(2, 3), 1, 1.0, 'char'] Accuracy 0.4957983193277311"""

log_reg = LogisticRegression(random_state=72, n_jobs=2, max_iter=5000)

param_grid = [
              {
                  'classifier__penalty' : ['l2'],
               'classifier__C' : np.logspace(-4, 4, 20),
               'classifier__solver' : ['lbfgs'],
               'classifier__multi_class': ['auto']}
              ]

pipe = Pipeline([('vectorizer', tfidf_vector),
                 ('classifier', log_reg)])
clf = GridSearchCV(pipe, param_grid, verbose=3)
clf.fit(X_train, y_train)

result = []
for config in configs:

    # Redefine vectorizer
    tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer, 
                                   ngram_range=config[0],
                                   min_df=config[1], max_df=config[2], analyzer=config[3])

    # Define classifier
    Random = RandomForestClassifier()

    # Create pipeline
    pipe_forest = Pipeline([('vectorizer', tfidf_vector),
                 ('classifier', Random)])

    # Fit model on training set
    pipe_forest.fit(X_train, y_train)

    # Predictions
    y_pred = pipe_forest.predict(X_test)

    # Print accuracy on test set
    print("CONFIG: ", config)
    print("Accuracy ", accuracy_score(y_test, y_pred))
    print("-----------------------")

    # Append to result
    result.append([config, accuracy_score(y_test, y_pred)])

tfid = TfidfVectorizer(tokenizer=spacy_tokenizer, ngram_range=(2,3), min_df=1, max_df=1.0, analyzer='char')

from sklearn.svm import SVC

clf = svm.SVC()
pipe_clf = Pipeline([('vectorizer', tfid),
                 ('classifier', clf)])
pipe_clf.fit(X_train, y_train)

a = pd.DataFrame(y_pred)
b = pd.DataFrame(df2['id'])
a = a[0]
b['difficulty'] = a

b['difficulty'] = ['A1' if x == 0
                   else 'A2' if x == 1
                   else 'B1' if x == 2
                   else 'B2' if x == 3
                   else 'C1' if x == 4
                   else 'C2'
                   for x in b.difficulty]

b.to_csv('deuxiemetestkaggleee.csv', header=True, index=False)

from sklearn.ensemble import VotingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
svm_clf_tweaked = SVC(probability=True, random_state=42)
tree_clf = DecisionTreeClassifier(random_state=42)
log_clf = LogisticRegression(solver="lbfgs", random_state=42)
svm_clf = SVC(gamma="scale", random_state=42)
soft_voting_clf = VotingClassifier(estimators=[('svm', pipe_clf), ('log', pipe)], 
                           voting='soft')


soft_voting_clf.fit(X_train, y_train) # training
y_pred_voting = soft_voting_clf.predict(X_test) # predicting
accuracy_score(y_test, y_pred_voting) # evaluating

from sklearn.svm import SVC

accuracy_test_log = accuracy_score(y_test, y_pred)
print('accuracy test: '+ str(accuracy_test_log))

a['difficulty'] = ['0' if x == 'A1'
                   else '1' if x == 'A2'
                   else '2' if x == 'B1'
                   else '3' if x == 'B2'
                   else '4' if x == 'C1'
                   else '5'
                   for x in df.difficulty]

a = pd.DataFrame(y_pred)
b = pd.DataFrame(df2['id'])
a = a[0]
b['difficulty'] = a
b.to_csv('premiertestkaggle.csv', header=True, index=False)

from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
grid={"C":np.logspace(-3,3,7), "penalty":["l1","l2"]}# l1 lasso l2 ridge
logreg=LogisticRegression()
logreg_cv=GridSearchCV(logreg,grid,cv=5)
pipe = Pipeline([('vectorizer', tfid),
                 ('classifier', logreg_cv)])
pipe.fit(X_train,y_train)

print("tuned hpyerparameters :(best parameters) ",logreg_cv.best_params_)
print("accuracy :",logreg_cv.best_score_)

classifier = LogisticRegression(solver = 'lbfgs', C=10, penalty='l2',fit_intercept=True,random_state=1234,n_jobs= 2)

# Create pipeline
## The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.
pipe = Pipeline([('vectorizer', tfid),
                 ('classifier', classifier)])

# Fit model on training set
pipe.fit(X_train, y_train)

df_new = pd.concat([df[df["oe_difficulty"] == 0].sample(len(df[df["oe_difficulty"] == 3])), df[df["oe_difficulty"] == 1].sample(len(df[df["oe_difficulty"] == 3])), df[df["oe_difficulty"] == 2].sample(len(df[df["oe_difficulty"] == 3])), df[df["oe_difficulty"] == 3],df[df["oe_difficulty"] == 4].sample(len(df[df["oe_difficulty"] == 3])),df[df["oe_difficulty"] == 5].sample(len(df[df["oe_difficulty"] == 3]))], axis=0).reset_index()
df_new

! pip install transformers

# Import generic wrappers
from transformers import AutoModel, AutoTokenizer 


# Define the model repo
model_name = "abhilash1910/french-roberta" 


# Download pytorch model
model = AutoModel.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)


# Transform input tokens 
inputs = tokenizer("Hello world!", return_tensors="pt")

# Model apply
outputs = model(**inputs)

df['difficulty'] = ['0' if x == 'A1'
                   else '1' if x == 'A2'
                   else '2' if x == 'B1'
                   else '3' if x == 'B2'
                   else '4' if x == 'C1'
                   else '5'
                   for x in df.difficulty]

encoder = OneHotEncoder(handle_unknown='ignore')
encoder_df = pd.DataFrame(encoder.fit_transform(df[['difficulty']]).toarray())
final_df = df.join(encoder_df)
final_df  =  final_df.rename({0:'A1',1:'A2', 2:'B1', 3:'B2', 4:'C1', 5:'C2'}, axis = 'columns')

df['difficulty'] = df['difficulty'].astype(int)

df['sentence'] = df['sentence'].astype(str)

df.to_csv('df1_fichier.csv', header=True, index=False)

val_size = int(0.2 * df.shape[0])  # 20% of the data

# Split the data into the training set and the validation set
X_train = final_df[val_size:]
X_val = final_df[:val_size]
X_train

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install transformers
# !pip install pytorch-lightning
# 
# # Load the RoBERTa tokenizer and model
#

from torch.utils.data import Dataset

attributes = ['A1','A2','B1','B2','C1','C2']

class UCC_Dataset(Dataset):

  def __init__(self, data_path, tokenizer,attributes ,max_token_len: int = 128, sample = 5000):
    self.data_path = data_path
    self.tokenizer = tokenizer
    self.attributes = attributes
    self.max_token_len = max_token_len
    self.sample = sample
    self._prepare_data()


  def _prepare_data(self):
    data = pd.read_csv(self.data_path)
    self.data = data
    
  def __len__(self):
    return len(self.data)

  def __getitem__(self, index):
    item = self.data.iloc[index]
    sentences = str(item.sentence)
    attributes = torch.FloatTensor(item[self.attributes])
    tokens = self.tokenizer.encode_plus(sentences,
                                        add_special_tokens=True,
                                        return_tensors='pt',
                                        truncation=True,
                                        padding='max_length',
                                        max_length=self.max_token_len,
                                        return_attention_mask = True)
    return {'input_ids': tokens.input_ids.flatten(), 'attention_mask': tokens.attention_mask.flatten(), 'labels': attributes}

import torch
from transformers import AutoTokenizer
model_name = 'camembert-base'
tokenizer = AutoTokenizer.from_pretrained(model_name)
camembert = CamembertForMaskedLM.from_pretrained('camembert-base')

ucc_ds = UCC_Dataset(train_path, tokenizer,attributes=attributes)
ucc_ds_val = UCC_Dataset(val_path, tokenizer,attributes=attributes ,sample=None)

ucc_ds.__getitem__(0)['labels'].shape, ucc_ds.__getitem__(0)['input_ids'].shape, ucc_ds.__getitem__(0)['attention_mask'].shape

import pytorch_lightning as pl
from torch.utils.data import DataLoader

class UCC_Data_Module(pl.LightningDataModule):

  def __init__(self, train_path, val_path, attributes, batch_size: int = 16, max_token_length: int = 128,  model_name='camembert-base'):
    super().__init__()
    self.train_path = train_path
    self.val_path = val_path
    self.attributes = attributes
    self.batch_size = batch_size
    self.max_token_length = max_token_length
    self.model_name = model_name
    self.tokenizer = AutoTokenizer.from_pretrained(model_name)

  def setup(self, stage = None):
    if stage in (None, "fit"):
      self.train_dataset = UCC_Dataset(self.train_path, attributes=self.attributes,tokenizer=self.tokenizer)
      self.test_dataset = UCC_Dataset(self.val_path,attributes=self.attributes ,tokenizer=self.tokenizer, sample=None)
    if stage == 'predict':
      self.test_dataset = UCC_Dataset(self.val_path,attributes=self.attributes ,tokenizer=self.tokenizer, sample=None)

  def train_dataloader(self):
    return DataLoader(self.train_dataset, batch_size = self.batch_size, num_workers=4, shuffle=True)

  def val_dataloader(self):
    return DataLoader(self.test_dataset, batch_size = self.batch_size, num_workers=4, shuffle=False)

  def predict_dataloader(self):
    return DataLoader(self.test_dataset, batch_size = self.batch_size, num_workers=4, shuffle=False)

ucc_data_module.setup()

ucc_data_module.train_dataloader()

len(ucc_data_module.train_dataloader())

"""#Model"""

from transformers import AutoModel, AdamW, get_cosine_schedule_with_warmup,CamembertForMaskedLM
import torch.nn as nn
import math
import torch.nn.functional as F

camembert = CamembertForMaskedLM.from_pretrained('camembert-base')

class UCC_Comment_Classifier(pl.LightningModule):

  def __init__(self, config: dict):
    super().__init__()
    self.config = config
    self.pretrained_model = camembert(config['model_name'], return_dict = True)
    self.hidden = torch.nn.Linear(self.pretrained_model.config.hidden_size, self.pretrained_model.config.hidden_size)
    self.classifier = torch.nn.Linear(self.pretrained_model.config.hidden_size, self.config['n_labels'])
    torch.nn.init.xavier_uniform_(self.classifier.weight)
    self.loss_func = nn.BCEWithLogitsLoss(reduction='mean')
    self.dropout = nn.Dropout()
    
  def forward(self, input_ids, attention_mask, labels=None):
    # roberta layer
    output = self.pretrained_model(input_ids=input_ids, attention_mask=attention_mask)
    pooled_output = torch.mean(output.last_hidden_state, 1)
    # final logits
    pooled_output = self.dropout(pooled_output)
    pooled_output = self.hidden(pooled_output)
    pooled_output = F.relu(pooled_output)
    pooled_output = self.dropout(pooled_output)
    logits = self.classifier(pooled_output)
    # calculate loss
    loss = 0
    if labels is not None:
      loss = self.loss_func(logits.view(-1, self.config['n_labels']), labels.view(-1, self.config['n_labels']))
    return loss, logits

  def training_step(self, batch, batch_index):
    loss, outputs = self(**batch)
    self.log("train loss ", loss, prog_bar = True, logger=True)
    return {"loss":loss, "predictions":outputs, "labels": batch["labels"]}

  def validation_step(self, batch, batch_index):
    loss, outputs = self(**batch)
    self.log("validation loss ", loss, prog_bar = True, logger=True)
    return {"val_loss": loss, "predictions":outputs, "labels": batch["labels"]}

  def predict_step(self, batch, batch_index):
    loss, outputs = self(**batch)
    return outputs

  def configure_optimizers(self):
    optimizer = AdamW(self.parameters(), lr=self.config['lr'], weight_decay=self.config['weight_decay'])
    total_steps = self.config['train_size']/self.config['batch_size']
    warmup_steps = math.floor(total_steps * self.config['warmup'])
    warmup_steps = math.floor(total_steps * self.config['warmup'])
    scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)
    return [optimizer],[scheduler]

  # def validation_epoch_end(self, outputs):
  #   losses = []
  #   for output in outputs:
  #     loss = output['val_loss'].detach().cpu()
  #     losses.append(loss)
  #   avg_loss = torch.mean(torch.stack(losses))
  #   self.log("avg_val_loss", avg_loss)

config = {
    'model_name': 'cmarkea/distilcamembert-base',
    'n_labels': len(attributes),
    'batch_size': 128,
    'lr': 1.5e-6,
    'warmup': 0.2, 
    'train_size': len(ucc_data_module.train_dataloader()),
    'weight_decay': 0.001,
    'n_epochs': 10
}

model = UCC_Comment_Classifier(config)

# datamodule
ucc_data_module = UCC_Data_Module(train_path, val_path, attributes=attributes, batch_size=config['batch_size'])
ucc_data_module.setup()

# model
model = UCC_Comment_Classifier(config)

# trainer and fit
trainer = pl.Trainer(max_epochs=config['n_epochs'], num_sanity_val_steps=50)
trainer.fit(model, ucc_data_module)

"""#Does not work"""

embedding_dim = 50
embedding_matrix = create_embedding_matrix('/content/data/training_data.csv',tokenizer.word_index, embedding_dim)
embedding_matrix

! pip install datasets

! pip install pytorch_lightning

!pip install transformers plotly==5.8.0 pyyaml==5.4.1 datasets pytorch-lightning > /dev/null 2>&1

from pprint import pprint
import functools

import torch
from torch.utils.data import DataLoader
import torch.nn.functional as F
import pytorch_lightning as pl
from transformers import AutoModelForSequenceClassification, CamembertForMaskedLM, AutoTokenizer, AutoConfig
from datasets import load_dataset
from sklearn.metrics import confusion_matrix, f1_score

import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from tqdm.notebook import tqdm

tokenizer = AutoTokenizer.from_pretrained('camembert-base')
camembert = CamembertForMaskedLM.from_pretrained('camembert-base')

df_new = pd.concat([df[df["oe_difficulty"] == 0].sample(len(df[df["oe_difficulty"] == 3])), df[df["oe_difficulty"] == 1].sample(len(df[df["oe_difficulty"] == 3])), df[df["oe_difficulty"] == 2].sample(len(df[df["oe_difficulty"] == 3])), df[df["oe_difficulty"] == 3],df[df["oe_difficulty"] == 4].sample(len(df[df["oe_difficulty"] == 3])),df[df["oe_difficulty"] == 5].sample(len(df[df["oe_difficulty"] == 3]))], axis=0).reset_index()
df_new

X_val['difficulty'].value_counts()

df['difficulty'] = ['0' if x == 'A1'
                   else '1' if x == 'A2'
                   else '2' if x == 'B1'
                   else '3' if x == 'B2'
                   else '4' if x == 'C1'
                   else '5'
                   for x in df.difficulty]

df2['difficulty'

encoder = OneHotEncoder(handle_unknown='ignore')
encoder_df = pd.DataFrame(encoder.fit_transform(df[['difficulty']]).toarray())
final_df = df.join(encoder_df)
final_df  =  final_df.rename({0:'A1',1:'A2', 2:'B1', 3:'B2', 4:'C1', 5:'C2'}, axis = 'columns')

df['difficulty'] = df['difficulty'].astype(int)

df

from pandas._libs.hashtable import value_count
df['difficulty'].value_counts()

#df = df.drop(['id'], axis = 1)
df2 = df2.drop(['id'], axis = 1)

df2['difficulty'] = 'A1'
df2['label'] = 1

df2

val_size = int(0.2 * df.shape[0])  # 20% of the data


# Split the data into the training set and the validation set
df_train = df[val_size:]
df_val = df[:val_size]

n_rows = df.shape[0]

# Calculate the number of rows that should be in the random sample (20% of the total number of rows)
n_sample = int(n_rows * 0.2)

# Get a random sample of rows from the data frame
df_val = df.sample(n=n_sample, random_state=42)

df_train = df[~df.index.isin(sample.index)]

df_train['difficulty'].value_counts()

df_val['difficulty'].value_counts()

df_train = df_train.drop(['id'], axis = 1)
df_val = df_val.drop(['id'], axis = 1)

df_val['difficulty'].value_counts()

df_train['label'] = ['0' if x == 'A1'
                   else '1' if x == 'A2'
                   else '2' if x == 'B1'
                   else '3' if x == 'B2'
                   else '4' if x == 'C1'
                   else '5'
                   for x in df_train.difficulty]

df_val['label'] = ['0' if x == 'A1'
                   else '1' if x == 'A2'
                   else '2' if x == 'B1'
                   else '3' if x == 'B2'
                   else '4' if x == 'C1'
                   else '5'
                   for x in df_val.difficulty]

df_train.to_csv('X_train111_fichier.csv', header=True, index=False)
df_val.to_csv('X_validation11_fichier.csv', header=True, index=False)

df2.to_csv('X_test1_fichier.csv', header=True, index=False)

df2

dataset = load_dataset("Vidalloka/train_dmml")

dataset

def tokenize_batch(samples, tokenizer):
    text = [sample["sentence"] for sample in samples]
    labels = torch.tensor([sample["label"] for sample in samples])
    str_labels = [sample["difficulty"] for sample in samples]
    # The tokenizer handles
    # - Tokenization (amazing right?)
    # - Padding (adding empty tokens so that each example has the same length)
    # - Truncation (cutting samples that are too long)
    # - Special tokens (in CamemBERT, each sentence ends with a special token </s>)
    # - Attention mask (a binary vector which tells the model which tokens to look at. For instance it will not compute anything if the token is a padding token)
    tokens = tokenizer(text, padding="longest", return_tensors="pt")

    return {"input_ids": tokens.input_ids, "attention_mask": tokens.attention_mask, "labels": labels, "str_labels": str_labels, "sentences": text}

pd_dataset = {split_name: split_data.to_pandas() for split_name, split_data in dataset.items()}
pd_dataset["validation"]

train_dataset, test_dataset,val_dataset = dataset.values()

val_dataset

val_dataloader = DataLoader(val_dataset, collate_fn=functools.partial(tokenize_batch, tokenizer=tokenizer), batch_size=16)
next(iter(val_dataloader))

def take_first_embedding(embeddings, attention_mask=None):
    return embeddings[:, 0]

def average_embeddings(embeddings, attention_mask):
    return (attention_mask[..., None] * embeddings).mean(1)

sentences = []
labels = []
str_labels = []
all_representations = torch.Tensor()

with torch.no_grad():
    for tokenized_batch in tqdm(val_dataloader):
        model_output = camembert(
            input_ids = tokenized_batch["input_ids"],
            attention_mask = tokenized_batch["attention_mask"],
            output_hidden_states=True
        )
        batch_representations = average_embeddings(model_output["hidden_states"][-1], tokenized_batch["attention_mask"])
        sentences.extend(tokenized_batch["sentences"])
        labels.extend(tokenized_batch["labels"])
        str_labels.extend(tokenized_batch["str_labels"])
        all_representations = torch.cat((all_representations, batch_representations), 0)

train_dataloader = DataLoader(
    dataset["train"], 
    batch_size=16, 
    shuffle=True, 
    collate_fn=functools.partial(tokenize_batch, tokenizer=tokenizer)
)
val_dataloader = DataLoader(
    dataset["validation"], 
    batch_size=16, 
    shuffle=False, 
    collate_fn=functools.partial(tokenize_batch, tokenizer=tokenizer)
)
test_dataloader = DataLoader(
    dataset["test"], 
    batch_size=16, 
    shuffle=False, 
    collate_fn=functools.partial(tokenize_batch, tokenizer=tokenizer)
)

batch = next(iter(train_dataloader))

print("\n".join(tokenizer.batch_decode(batch["input_ids"])))
batch["labels"]

val_dataset

class LightningModel(pl.LightningModule):
    def __init__(self, model_name, num_labels, lr, weight_decay, from_scratch=False):
        super().__init__()
        self.save_hyperparameters()
        if from_scratch:
            # Si `from_scratch` est vrai, on charge uniquement la config (nombre de couches, hidden size, etc.) et pas les poids du modèle 
            config = AutoConfig.from_pretrained(
                model_name, num_labels=num_labels
            )
            self.model = AutoModelForSequenceClassification.from_config(config)
        else:
            # Cette méthode permet de télécharger le bon modèle pré-entraîné directement depuis le Hub de HuggingFace sur lequel sont stockés de nombreux modèles
            self.model = AutoModelForSequenceClassification.from_pretrained(
                model_name, num_labels=num_labels
            )
        self.lr = lr
        self.weight_decay = weight_decay
        self.num_labels = self.model.num_labels

    def forward(self, batch):
        return self.model(
            input_ids=batch["input_ids"],
            attention_mask=batch["attention_mask"]
        )

    def training_step(self, batch):
        out = self.forward(batch)

        logits = out.logits
        # -------- MASKED --------
        loss_fn = torch.nn.CrossEntropyLoss()
        loss = loss_fn(logits.view(-1, self.num_labels), batch["labels"].view(-1))

        # ------ END MASKED ------

        self.log("train/loss", loss)

        return loss

    def validation_step(self, batch, batch_index):
        labels = batch["labels"]
        out = self.forward(batch)

        preds = torch.max(out.logits, -1).indices
        # -------- MASKED --------
        acc = (batch["labels"] == preds).float().mean()
        # ------ END MASKED ------
        self.log("valid/acc", acc)

        f1 = f1_score(batch["labels"].cpu().tolist(), preds.cpu().tolist(), average="macro")
        self.log("valid/f1", f1)

    def predict_step(self, batch, batch_idx):
        """La fonction predict step facilite la prédiction de données. Elle est 
        similaire à `validation_step`, sans le calcul des métriques.
        """
        out = self.forward(batch)

        return torch.max(out.logits, -1).indices

    def configure_optimizers(self):
        return torch.optim.AdamW(
            self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay
        )

lightning_model = LightningModel("camembert-base", 6, lr=3e-5, weight_decay=2.)

model_checkpoint = pl.callbacks.ModelCheckpoint(monitor="valid/acc", mode="max")

camembert_trainer = pl.Trainer(
    max_epochs=20,
    gpus=1,
    callbacks=[
        pl.callbacks.EarlyStopping(monitor="valid/acc", patience=4, mode="max"),
        model_checkpoint,
    ]
)

train_dataset

camembert_trainer.fit(lightning_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)

from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score


class EvaluationMetrics:
    def __init__(self, true,pred):
        self.__precision = round(precision_score(true, pred, average='weighted'),4),
        self.__recall = round(recall_score(true, pred, average='weighted'),4),
        self.__f1 = round(f1_score(true, pred, average='weighted'),4),
        self.__accuracy = round(accuracy_score(true, pred),4),
        self.__confusion_matrix = confusion_matrix(true,pred),
        self.__config = None

    def getPrecision(self):
        return self.__precision[0]

    def getRecall(self):
        return self.__recall[0]

    def getF1(self):
        return self.__f1[0]

    def getAccuracy(self):
        return self.__accuracy[0]
    
    def getConfMatrix(self):
        return self.__confusion_matrix[0]

    def setConfig(self, config):
        self.__config = config

    def __gt__(self, other):
        return self.__accuracy > other.getAccuracy()

    def __str__(self):
        txtstr = (f"Precision\t{self.__precision}"
              f"\nRecall\t{self.__recall}"
              f"\nF1-score\t{self.__f1}"
              f"\nAccuracy\t{self.__accuracy}"
              f"\nConfusion Matrix\n{self.__confusion_matrix}")
        if self.__config is not None:
            txtstr = txtstr + f"\nConfig\t{self.__config}"
        return txtstr

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir ./lightning_logs/

lightning_model = LightningModel.load_from_checkpoint(checkpoint_path=model_checkpoint.best_model_path)

ID_TO_LABEL = dataset["train"].features["difficulty"].names

ID_TO_LABEL = dict(zip(range(6), ('A1', 'A2', 'B1', 'B2', 'C1', 'C2',)))
label_names = list(ID_TO_LABEL.values())

def get_preds(model, tokenizer, sentence):
    tokenized_sentence = tokenizer(sentence, return_tensors="pt")
    input_ids, attention_mask = tokenized_sentence.input_ids, tokenized_sentence.attention_mask

    out = model(
        input_ids=tokenized_sentence.input_ids,
        attention_mask=tokenized_sentence.attention_mask
    )

    logits = out.logits

    probas = torch.softmax(logits, -1).squeeze()

    pred = torch.argmax(probas)

    return ID_TO_LABEL[pred], probas[pred].item()

camembert_predict = camembert_trainer.predict(lightning_model, dataloaders=val_dataloader)

camembert_predict = torch.cat(camembert_predict, -1)

camembert_predict

df_val['difficulty'].value_counts()

print(classification_report(dataset['validation']['label'], camembert_predict, target_names = label_names))

df_val['difficulty'].value_counts()

from sklearn import metrics
plt.figure(figsize=(15, 8))
for i, label in enumerate(label_names):
  fpr, tpr, _ = metrics.roc_curve(
      dataset['validation']['label'][:, i].astype(int), camembert_predict[:, i])
  auc = metrics.roc_auc_score(
      dataset['validation']['label'][:, i].astype(int), camembert_predict[:, i])
  plt.plot(fpr, tpr, label='%s %g' % (label, auc))
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='lower right')
plt.title('RoBERTa Trained on UCC Datatset - AUC ROC')

test_dataloader = DataLoader(
    dataset["test"], 
    batch_size=16, 
    shuffle=False, 
    collate_fn=functools.partial(tokenize_batch, tokenizer=tokenizer)
)

#preds = camembert_trainer.predict(lightning_model, dataloaders=test_dataloader)
#preds = torch.cat(preds, -1) # ?

test_df = dataset["test"].to_pandas()
test_df
#test_df.label = preds.numpy()
#test_df.difficulty = test_df.label.apply(lambda x: label_names[x])
#test_df.index.name = 'id'
#test_df.drop(columns=["sentence", "label"], inplace=True)

test_dataloader = DataLoader(test_dataset, collate_fn=functools.partial(tokenize_batch, tokenizer=tokenizer), batch_size=16)
test_dataloader

df2

camembert_predict = camembert_trainer.predict(lightning_model, dataloaders=test_dataloader)

print(classification_report(dataset['validation']['label'], camembert_predict, target_names = label_names))

camembert_predict = torch.cat(camembert_predict, -1)
camembert_predict

df_test_cnn= pd.DataFrame(camembert_predict)

a = pd.DataFrame(camembert_predict)

df_test_cnn[0] = ['A1' if x == 0
                   else 'A2' if x == 1
                   else 'B1' if x == 2
                   else 'B2' if x == 3
                   else 'C1' if x == 4
                   else 'C2'
                   for x in df_test_cnn[0]]
df_test_cnn

b = pd.DataFrame(df2['id'])
b['difficulty'] = df_test_cnn[0]
b.to_csv('test_cnn2.csv', header=True, index=False)

val_dataloader = DataLoader(val_dataset, collate_fn=functools.partial(tokenize_batch, tokenizer=tokenizer), batch_size=16)
next(iter(val_dataloader))
train_dataloader = DataLoader(train_dataset, collate_fn=functools.partial(tokenize_batch, tokenizer=tokenizer), batch_size=16, shuffle = True)
next(iter(val_dataloader))

class UCC_Data_Module(pl.LightningModule):

  def __init__(self, train_path, val_path, attributes, batch_size: int = 16, max_token_length: int = 128,  model_name='camembert-base'):
    super().__init__()
    self.train_path = train_path
    self.val_path = val_path
    self.attributes = attributes
    self.batch_size = batch_size
    self.max_token_length = max_token_length
    self.model_name = model_name
    self.tokenizer = AutoTokenizer.from_pretrained(model_name)

  def setup(self, stage = None):
    if stage in (None, "fit"):
      self.train_dataset = UCC_Dataset(self.train_path, attributes=self.attributes,tokenizer=self.tokenizer)
      self.test_dataset = UCC_Dataset(self.val_path,attributes=self.attributes ,tokenizer=self.tokenizer, sample=None)
    if stage == 'predict':
      self.test_dataset = UCC_Dataset(self.val_path,attributes=self.attributes ,tokenizer=self.tokenizer, sample=None)

  def train_dataloader(self):
    return DataLoader(self.train_dataset, batch_size = self.batch_size, num_workers=4, shuffle=True)

  def val_dataloader(self):
    return DataLoader(self.test_dataset, batch_size = self.batch_size, num_workers=4, shuffle=False)

  def predict_dataloader(self):
    return DataLoader(self.test_dataset, batch_size = self.batch_size, num_workers=4, shuffle=False)